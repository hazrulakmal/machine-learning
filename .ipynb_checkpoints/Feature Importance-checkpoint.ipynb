{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a952cf1",
   "metadata": {},
   "source": [
    "## Machine Learning Model\n",
    "\n",
    "Recently, driven by the need to maximise the use of big data, ML methods has been widely employed in many application across various indutries. However, ML is deemed to be increadibily difficult to interpret due to its nature model complexity. This project focuses on explaining why model makes certain predictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21a711b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics, linear_model, tree, naive_bayes, neighbors, ensemble,\\\n",
    "                    neural_network, svm, decomposition, manifold\n",
    "from rulefit import RuleFit\n",
    "import statsmodels.api as sm\n",
    "from interpret.glassbox import ExplainableBoostingClassifier\n",
    "from interpret import show\n",
    "from interpret.perf import ROC\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import Normalizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34840f22",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d27e1c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LotFrontage     259\n",
       "GarageType       81\n",
       "GarageYrBlt      81\n",
       "GarageFinish     81\n",
       "GarageQual       81\n",
       "GarageCond       81\n",
       "BsmtFinType2     38\n",
       "BsmtExposure     38\n",
       "BsmtQual         37\n",
       "BsmtCond         37\n",
       "BsmtFinType1     37\n",
       "MasVnrArea        8\n",
       "MasVnrType        8\n",
       "Electrical        1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "house =  pd.read_csv(\"src/train.csv\")\n",
    "ml_dt = house.drop([\"PoolQC\", \"Fence\", \"FireplaceQu\", \"Alley\", \"MiscFeature\", \"Id\"], axis=1)\n",
    "missing = ml_dt.isnull().sum().sort_values(ascending=False)\n",
    "missing = missing[missing != 0]\n",
    "missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7efc6c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1094 entries, 0 to 1459\n",
      "Data columns (total 75 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   MSSubClass     1094 non-null   int64  \n",
      " 1   MSZoning       1094 non-null   object \n",
      " 2   LotFrontage    1094 non-null   float64\n",
      " 3   LotArea        1094 non-null   int64  \n",
      " 4   Street         1094 non-null   object \n",
      " 5   LotShape       1094 non-null   object \n",
      " 6   LandContour    1094 non-null   object \n",
      " 7   Utilities      1094 non-null   object \n",
      " 8   LotConfig      1094 non-null   object \n",
      " 9   LandSlope      1094 non-null   object \n",
      " 10  Neighborhood   1094 non-null   object \n",
      " 11  Condition1     1094 non-null   object \n",
      " 12  Condition2     1094 non-null   object \n",
      " 13  BldgType       1094 non-null   object \n",
      " 14  HouseStyle     1094 non-null   object \n",
      " 15  OverallQual    1094 non-null   int64  \n",
      " 16  OverallCond    1094 non-null   int64  \n",
      " 17  YearBuilt      1094 non-null   int64  \n",
      " 18  YearRemodAdd   1094 non-null   int64  \n",
      " 19  RoofStyle      1094 non-null   object \n",
      " 20  RoofMatl       1094 non-null   object \n",
      " 21  Exterior1st    1094 non-null   object \n",
      " 22  Exterior2nd    1094 non-null   object \n",
      " 23  MasVnrType     1094 non-null   object \n",
      " 24  MasVnrArea     1094 non-null   float64\n",
      " 25  ExterQual      1094 non-null   object \n",
      " 26  ExterCond      1094 non-null   object \n",
      " 27  Foundation     1094 non-null   object \n",
      " 28  BsmtQual       1094 non-null   object \n",
      " 29  BsmtCond       1094 non-null   object \n",
      " 30  BsmtExposure   1094 non-null   object \n",
      " 31  BsmtFinType1   1094 non-null   object \n",
      " 32  BsmtFinSF1     1094 non-null   int64  \n",
      " 33  BsmtFinType2   1094 non-null   object \n",
      " 34  BsmtFinSF2     1094 non-null   int64  \n",
      " 35  BsmtUnfSF      1094 non-null   int64  \n",
      " 36  TotalBsmtSF    1094 non-null   int64  \n",
      " 37  Heating        1094 non-null   object \n",
      " 38  HeatingQC      1094 non-null   object \n",
      " 39  CentralAir     1094 non-null   object \n",
      " 40  Electrical     1094 non-null   object \n",
      " 41  1stFlrSF       1094 non-null   int64  \n",
      " 42  2ndFlrSF       1094 non-null   int64  \n",
      " 43  LowQualFinSF   1094 non-null   int64  \n",
      " 44  GrLivArea      1094 non-null   int64  \n",
      " 45  BsmtFullBath   1094 non-null   int64  \n",
      " 46  BsmtHalfBath   1094 non-null   int64  \n",
      " 47  FullBath       1094 non-null   int64  \n",
      " 48  HalfBath       1094 non-null   int64  \n",
      " 49  BedroomAbvGr   1094 non-null   int64  \n",
      " 50  KitchenAbvGr   1094 non-null   int64  \n",
      " 51  KitchenQual    1094 non-null   object \n",
      " 52  TotRmsAbvGrd   1094 non-null   int64  \n",
      " 53  Functional     1094 non-null   object \n",
      " 54  Fireplaces     1094 non-null   int64  \n",
      " 55  GarageType     1094 non-null   object \n",
      " 56  GarageYrBlt    1094 non-null   float64\n",
      " 57  GarageFinish   1094 non-null   object \n",
      " 58  GarageCars     1094 non-null   int64  \n",
      " 59  GarageArea     1094 non-null   int64  \n",
      " 60  GarageQual     1094 non-null   object \n",
      " 61  GarageCond     1094 non-null   object \n",
      " 62  PavedDrive     1094 non-null   object \n",
      " 63  WoodDeckSF     1094 non-null   int64  \n",
      " 64  OpenPorchSF    1094 non-null   int64  \n",
      " 65  EnclosedPorch  1094 non-null   int64  \n",
      " 66  3SsnPorch      1094 non-null   int64  \n",
      " 67  ScreenPorch    1094 non-null   int64  \n",
      " 68  PoolArea       1094 non-null   int64  \n",
      " 69  MiscVal        1094 non-null   int64  \n",
      " 70  MoSold         1094 non-null   int64  \n",
      " 71  YrSold         1094 non-null   int64  \n",
      " 72  SaleType       1094 non-null   object \n",
      " 73  SaleCondition  1094 non-null   object \n",
      " 74  SalePrice      1094 non-null   int64  \n",
      "dtypes: float64(3), int64(34), object(38)\n",
      "memory usage: 649.6+ KB\n"
     ]
    }
   ],
   "source": [
    "ml_dt = ml_dt.dropna()\n",
    "ml_dt.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd06a7e4",
   "metadata": {},
   "source": [
    "Remove missing values technique is not an idea solution for model performance in general but this project focuses more on  model intrepretaion rather than building the correct model. 25% of the data have been ommitted which is consider a huge portion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb29d6c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1094 entries, 0 to 1459\n",
      "Data columns (total 37 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   MSSubClass     1094 non-null   int64  \n",
      " 1   LotFrontage    1094 non-null   float64\n",
      " 2   LotArea        1094 non-null   int64  \n",
      " 3   OverallQual    1094 non-null   int64  \n",
      " 4   OverallCond    1094 non-null   int64  \n",
      " 5   YearBuilt      1094 non-null   int64  \n",
      " 6   YearRemodAdd   1094 non-null   int64  \n",
      " 7   MasVnrArea     1094 non-null   float64\n",
      " 8   BsmtFinSF1     1094 non-null   int64  \n",
      " 9   BsmtFinSF2     1094 non-null   int64  \n",
      " 10  BsmtUnfSF      1094 non-null   int64  \n",
      " 11  TotalBsmtSF    1094 non-null   int64  \n",
      " 12  1stFlrSF       1094 non-null   int64  \n",
      " 13  2ndFlrSF       1094 non-null   int64  \n",
      " 14  LowQualFinSF   1094 non-null   int64  \n",
      " 15  GrLivArea      1094 non-null   int64  \n",
      " 16  BsmtFullBath   1094 non-null   int64  \n",
      " 17  BsmtHalfBath   1094 non-null   int64  \n",
      " 18  FullBath       1094 non-null   int64  \n",
      " 19  HalfBath       1094 non-null   int64  \n",
      " 20  BedroomAbvGr   1094 non-null   int64  \n",
      " 21  KitchenAbvGr   1094 non-null   int64  \n",
      " 22  TotRmsAbvGrd   1094 non-null   int64  \n",
      " 23  Fireplaces     1094 non-null   int64  \n",
      " 24  GarageYrBlt    1094 non-null   float64\n",
      " 25  GarageCars     1094 non-null   int64  \n",
      " 26  GarageArea     1094 non-null   int64  \n",
      " 27  WoodDeckSF     1094 non-null   int64  \n",
      " 28  OpenPorchSF    1094 non-null   int64  \n",
      " 29  EnclosedPorch  1094 non-null   int64  \n",
      " 30  3SsnPorch      1094 non-null   int64  \n",
      " 31  ScreenPorch    1094 non-null   int64  \n",
      " 32  PoolArea       1094 non-null   int64  \n",
      " 33  MiscVal        1094 non-null   int64  \n",
      " 34  MoSold         1094 non-null   int64  \n",
      " 35  YrSold         1094 non-null   int64  \n",
      " 36  SalePrice      1094 non-null   int64  \n",
      "dtypes: float64(3), int64(34)\n",
      "memory usage: 324.8 KB\n"
     ]
    }
   ],
   "source": [
    "object_features = ml_dt.select_dtypes(include=['object'])\n",
    "numerical_features = ml_dt.select_dtypes(include=['int64', \"float64\"])\n",
    "\n",
    "object_features_encode = pd.get_dummies(object_features)\n",
    "numerical_features.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "618e14a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SalePrice        1.000000\n",
       "OverallQual      0.795437\n",
       "GrLivArea        0.707481\n",
       "GarageCars       0.652103\n",
       "GarageArea       0.620772\n",
       "TotalBsmtSF      0.617741\n",
       "1stFlrSF         0.617692\n",
       "FullBath         0.578299\n",
       "TotRmsAbvGrd     0.560521\n",
       "YearBuilt        0.523434\n",
       "YearRemodAdd     0.519806\n",
       "GarageYrBlt      0.502248\n",
       "MasVnrArea       0.485409\n",
       "Fireplaces       0.458182\n",
       "BsmtFinSF1       0.378678\n",
       "LotFrontage      0.343978\n",
       "OpenPorchSF      0.338600\n",
       "WoodDeckSF       0.330286\n",
       "2ndFlrSF         0.302569\n",
       "LotArea          0.302268\n",
       "HalfBath         0.259469\n",
       "BsmtFullBath     0.223948\n",
       "BsmtUnfSF        0.191247\n",
       "BedroomAbvGr     0.168489\n",
       "EnclosedPorch    0.161711\n",
       "OverallCond      0.138511\n",
       "KitchenAbvGr     0.115382\n",
       "ScreenPorch      0.106479\n",
       "PoolArea         0.092085\n",
       "MSSubClass       0.089478\n",
       "MoSold           0.052584\n",
       "BsmtHalfBath     0.041341\n",
       "BsmtFinSF2       0.036923\n",
       "MiscVal          0.036001\n",
       "3SsnPorch        0.033947\n",
       "YrSold           0.006723\n",
       "LowQualFinSF     0.003541\n",
       "Name: SalePrice, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr = numerical_features.corr()\n",
    "abs(corr[\"SalePrice\"]).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ded0bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0bfdca45",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rand' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\HAZRUL~1\\AppData\\Local\\Temp/ipykernel_21988/3895524131.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumerical_features\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"SalePrice\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumerical_features\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"SalePrice\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_reg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test_reg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.15\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mct\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mColumnTransformer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'normalize'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNormalizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mremainder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'passthrough'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'rand' is not defined"
     ]
    }
   ],
   "source": [
    "x = numerical_features.drop([\"SalePrice\"], axis=1).copy()\n",
    "y = numerical_features[\"SalePrice\"]\n",
    "X_train, X_test, y_train_reg, y_test_reg = train_test_split(x, y, test_size=0.15, random_state=rand)\n",
    "\n",
    "ct = ColumnTransformer([('normalize', Normalizer(), x.columns)], remainder='passthrough')\n",
    "X_train = ct.fit_transform(X_train)\n",
    "X_test = ct.transform(X_test)\n",
    "y_train_reg = np.log(y_train_reg )\n",
    "y_test_reg = np.log(y_test_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842359c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a471951d",
   "metadata": {},
   "source": [
    "## Training and Evaluating various Regression Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db910569",
   "metadata": {},
   "source": [
    "1. instance-based machine learning model, *lazy learner*\n",
    "    - during inference, it employs training data to calculate the similarity between points and generate predictions based on that.\n",
    "\n",
    "\n",
    "2. model-based machine learning technique, *eager learner*\n",
    "    - during inference, it learns formula, coefficient, bias, paramters, weight which it then leverages to estimate the true value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36cbc722",
   "metadata": {},
   "source": [
    "we compare and contrast a few linear models.\n",
    "\n",
    "    1. Linear Regression\n",
    "        - as the name suggest, the model assumes linearity between relationhips of the features and the target variable. Prediction is a result of a linear combination of the X features.\n",
    "    \n",
    "    2. Polynomial Regression\n",
    "        - extend linear model by adding polynomial terms.\n",
    "    \n",
    "    3. Linear interact \n",
    "        - capture the interactions between the features. \n",
    "    \n",
    "    4. Ridge Regression\n",
    "        - Although OLS (ordinary least square) does a good job in fitting the model to the features by minimising the error term, it does it with without considering overfitting. OLS treats each feature equally, so the model becomes more complex as each variable is added. Ridge regression uses regularization to minimise the weight of coefficients that do not contribute to the outcome with penalty term called L2 norm. \n",
    "    \n",
    "    5. RuleFit \n",
    "        - is a regularised linear regression expanded to include feature interactions in the forms of rules. it can be used to solve both classification and regression problems. \n",
    "    \n",
    "    6. knn (K-nearest neighbour algorithms)\n",
    "        - method based on locality assumptions. it predicts a values correspond to similiar data points that are close to each other.\n",
    "    \n",
    "    7. Random forest\n",
    "        - combine many decision tress together to make decision. different trees randomly sample feature combination on random sample data. ensemble methods mean that the model combine more than one submodels to generate predicitons. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95818e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand = 10\n",
    "reg_models = {\n",
    "        #Generalized Linear Models (GLMs)\n",
    "        'linear':{'model': linear_model.LinearRegression()}, \n",
    "        'linear_poly':{'model': make_pipeline(PolynomialFeatures(degree=2),\n",
    "                              linear_model.LinearRegression(fit_intercept=False)) },\n",
    "        'linear_interact':{'model': make_pipeline(PolynomialFeatures(interaction_only=True),\n",
    "                              linear_model.LinearRegression(fit_intercept=False)) },\n",
    "        'ridge':{'model': linear_model.RidgeCV(alphas=[1e-3, 1e-2, 1e-1, 1]) }, \n",
    "        #Trees  \n",
    "        'decision_tree':{'model': tree.DecisionTreeRegressor(max_depth=7, random_state=rand)},\n",
    "        #Ensemble Methods\n",
    "        'random_forest':{'model':ensemble.RandomForestRegressor(max_depth=7, random_state=rand)}, \n",
    "        #RuleFit\n",
    "        'rulefit':{'model': RuleFit(max_rules=150, rfmode='regress', random_state=rand)}, \n",
    "        #Nearest Neighbors\n",
    "        'knn':{'model': neighbors.KNeighborsRegressor(n_neighbors=7)}, \n",
    "        #Neural Networks\n",
    "        'mlp':{'model':neural_network.MLPRegressor(hidden_layer_sizes=(21,), max_iter=500, \n",
    "                                                   early_stopping=True, random_state=rand)}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a07c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name in reg_models.keys():\n",
    "    if model_name != 'rulefit':\n",
    "        fitted_model = reg_models[model_name]['model'].fit(X_train, y_train_reg)\n",
    "    else:\n",
    "        fitted_model = reg_models[model_name]['model'].fit(X_train, y_train_reg.values, x.columns)\n",
    "    y_train_pred = fitted_model.predict(X_train)\n",
    "    y_test_pred = fitted_model.predict(X_test)\n",
    "    reg_models[model_name]['fitted'] = fitted_model\n",
    "    reg_models[model_name]['preds'] = y_test_pred\n",
    "    reg_models[model_name]['RMSE_train'] = math.sqrt(metrics.mean_squared_error(y_train_reg, y_train_pred))\n",
    "    reg_models[model_name]['RMSE_test'] = math.sqrt(metrics.mean_squared_error(y_test_reg, y_test_pred))\n",
    "    reg_models[model_name]['R2_test'] = metrics.r2_score(y_test_reg, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9edbac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reg_metrics = pd.DataFrame.from_dict(reg_models, 'index')[['RMSE_train', 'RMSE_test', 'R2_test']]\n",
    "reg_metrics.sort_values(by='RMSE_test').style.\\\n",
    "    background_gradient(cmap='viridis', low=1, high=0.3, subset=['RMSE_train', 'RMSE_test']).\\\n",
    "    background_gradient(cmap='plasma', low=0.3, high=1, subset=['R2_test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea40871",
   "metadata": {},
   "source": [
    "When ML methods are employed, we are often dealing with complex relationships between features. \n",
    "One way of reducing the complexity in visualising is by doing dimensionality reduction methods. \n",
    "\n",
    "Dimensionality Reduction technique has many application throughout any project pipilines. some leverage the technique purely to find pattern visually, some extended the concept to feature selection and enginering, oulier detection, model debugging.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee83993",
   "metadata": {},
   "source": [
    "## Feature Importance\n",
    "\n",
    "Understanding intrinsically interpretable (white-box) model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d49442",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c94547",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "coefs_lm = reg_models['linear']['fitted'].coef_\n",
    "intercept_lm = reg_models['linear']['fitted'].intercept_\n",
    "print('coefficients:\\t%s' % coefs_lm)\n",
    "print('intercept:\\t%s' % intercept_lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0c34c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('ŷ = %0.2f + %0.4fX₁ + %0.4fX₂ + %0.3fX₃ + ...' %\\\n",
    "      (intercept_lm, coefs_lm[0], coefs_lm[1], coefs_lm[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56eb568",
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_df = pd.DataFrame({'feature':x.columns.values.tolist(),\\\n",
    "                        'coef': coefs_lm})\n",
    "print(coef_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b123adac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train_df = pd.DataFrame(X_train)\n",
    "\n",
    "#important data manipulation\n",
    "def transform_col_name(y_list, x_list):\n",
    "    #take a list of original colnames and convert it to a new colname\n",
    "    colum_x = {}\n",
    "    for i, v in zip(y_list, x_list):\n",
    "        colum_x[i] =v \n",
    "    return colum_x\n",
    "\n",
    "colum_x_name = transform_col_name(x_train_df.columns, numerical_features.columns)\n",
    "x_train_df.rename(columns=colum_x_name, inplace=True)\n",
    "y_train_df = pd.DataFrame({\"SalesPrice\": y_train_reg})\n",
    "y_index= y_train_df.reset_index().drop(columns = [\"index\"]) #indexes of both df must be identical so that y and x train can be plugged into stast regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8115af6a",
   "metadata": {},
   "source": [
    "**Note that** Extracting more information about regression model can't be done through sklearn. We need to use stastmodel to get this information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b17cb28",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lineareg = sm.OLS(y_index, sm.add_constant(x_train_df))\n",
    "lineareg = lineareg.fit()\n",
    "lineareg.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a334eb9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "summary_df = lineareg.summary2().tables[1]\n",
    "summary_df = summary_df.drop(['const']).reset_index().rename(columns={'index':'feature'})\n",
    "summary_df['t_abs'] = abs(summary_df['t'])\n",
    "summary_df.sort_values(by='t_abs', ascending=False).style.\\\n",
    "    background_gradient(cmap='plasma_r', low=0, high=0.1, subset=['P>|t|']).\\\n",
    "    background_gradient(cmap='plasma_r', low=0, high=0.1, subset=['t_abs'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33348c5",
   "metadata": {},
   "source": [
    "### Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d098fa84",
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs_ridge = reg_models['ridge']['fitted'].coef_\n",
    "coef_ridge_df = pd.DataFrame({'feature':x_train_df.columns.values.tolist(),\\\n",
    "                        'coef_linear': coefs_lm,\\\n",
    "                        'coef_ridge': coefs_ridge})\n",
    "coef_ridge_df.style.\\\n",
    "    background_gradient(cmap='viridis_r', low=0.3, high=0.2, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1744612",
   "metadata": {},
   "source": [
    "regularisation can only work if we choose the hyperparameter correctly. in this case, we let sklearn chooses the optimal alpha for us. we can firgure out the optimal aplha by iterating through many possible alpha and firgure out which parameter was the est. The higher the alpha, the higher the regularization. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b104ddd4",
   "metadata": {},
   "source": [
    "## Decision Tree (CART)\n",
    "\n",
    "There are many kind of decision tree models and most of them are not relly very interpretable because they use ensemble mehods(boosting, bagging and stacking). CART decision tree is one of the few decision trees that is intrepretable because it is build upon a mathematical formula that we can reverse engineer to look for each feature contributions. \n",
    "\n",
    "Some features more often in the tree decision.All the sum of the relative decrease in the Gini index throughout the tree is tallied, and the contribution of each feature is a percentage of this reduction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608a6717",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_imp_df = pd.DataFrame({'feature':x_train_df.columns.values.tolist(),\\\n",
    "                        'importance': reg_models['decision_tree']['fitted'].feature_importances_}).\\\n",
    "            sort_values(by='importance', ascending=False)\n",
    "dt_imp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7aef205",
   "metadata": {},
   "source": [
    "## Rule Fit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1390450",
   "metadata": {},
   "source": [
    "Rule fit is a hybrid model that takes advantage of decision rules and lasso regression. The rulefit implementation used in this project uses gradient boosting decsion tree. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8bdead",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rulefit_df = reg_models['rulefit']['fitted'].get_rules()\n",
    "rulefit_df = rulefit_df[rulefit_df.coef != 0].sort_values(by=\"importance\", ascending=False)\n",
    "rulefit_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9afe96fe",
   "metadata": {},
   "source": [
    "The linear coefficient can be interpret as we would any linear regression coeeficient. the rule captures the interactions and can be treated as binary features in a linear regression. for example if the a house has a fireplace with value more than 9. the coeeficient will be added to sales price. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
